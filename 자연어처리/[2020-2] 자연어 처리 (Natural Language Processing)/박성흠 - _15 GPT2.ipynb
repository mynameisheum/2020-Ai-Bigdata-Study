{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"박성흠 - _15 GPT2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zBjBNQX8kQfh"},"source":["# GPT(Generative Pre-trained Transformer) 2\n","\n","* 참고: https://github.com/NLP-kr/tensorflow-ml-nlp-tf2"]},{"cell_type":"markdown","metadata":{"id":"gKeqNH_dkTmT"},"source":["* OpenAI에서 GPT 모델 제안\n","* 매우 큰 자연어 처리 데이터를 활용해 비지도 학습으로 사전 학습 후 학습된 가중치를 활용해 파인 튜닝\n","* BERT와 마찬가지로 트랜스포머 모델이지만, BERT는 트랜스포머의 인코더 구조만 사용하고, GPT는 트랜스포머의 디코더 구조(순방향 어텐션)만 사용\n","\n","* GPT2는 GPT1에서 개선되어 레이어 정규화가 부분 블록의 입력쪽에서 사용되고, 셀프 어텐션 이후에 레이어 정규화 적용\n","* GPT2는 GPT1에 비교해 크기가 매우 커진 향상된 모델 사용"]},{"cell_type":"markdown","metadata":{"id":"sDCr0YqjbfLJ"},"source":["## 라이브러리"]},{"cell_type":"code","metadata":{"id":"_ixYBCR8bguE","executionInfo":{"status":"ok","timestamp":1604926912975,"user_tz":-540,"elapsed":148742,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"572b6381-f832-4253-c621-deb7651e8532","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install transformers==2.11.0\n","!pip install tensorflow==2.2.0\n","!pip install sentencepiece==0.1.85\n","!pip install gluonnlp==0.9.1\n","!pip install mxnet==1.6.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers==2.11.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n","\u001b[K     |████████████████████████████████| 675kB 14.4MB/s \n","\u001b[?25hCollecting tokenizers==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 29.0MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (3.0.12)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 54.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (1.18.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (20.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 46.4MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==2.11.0) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==2.11.0) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (0.17.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (3.0.4)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=3dc07195b60a860f12f0ec8b7c15beae300e73226ab7b531f642cdb87667fcba\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.7.0 transformers-2.11.0\n","Collecting tensorflow==2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n","\u001b[K     |████████████████████████████████| 516.2MB 30kB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.10.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.18.5)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.10.0)\n","Collecting tensorboard<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 43.9MB/s \n","\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n","\u001b[K     |████████████████████████████████| 460kB 49.3MB/s \n","\u001b[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.4.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.6.3)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.12.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.15.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.12.4)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.35.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.33.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.17.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (50.3.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n","Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","Successfully installed tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n","Collecting sentencepiece==0.1.85\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 9.1MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","  Found existing installation: sentencepiece 0.1.94\n","    Uninstalling sentencepiece-0.1.94:\n","      Successfully uninstalled sentencepiece-0.1.94\n","Successfully installed sentencepiece-0.1.85\n","Collecting gluonnlp==0.9.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/27/07b57d22496ed6c98b247e578712122402487f5c265ec70a747900f97060/gluonnlp-0.9.1.tar.gz (252kB)\n","\u001b[K     |████████████████████████████████| 256kB 9.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp==0.9.1) (1.18.5)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp==0.9.1) (0.29.21)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp==0.9.1) (20.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp==0.9.1) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp==0.9.1) (2.4.7)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.9.1-cp36-cp36m-linux_x86_64.whl size=470039 sha256=28441c891324ac1ca36b59b7bfd072dade1d266e4f83d666af8ca6e9ebb344eb\n","  Stored in directory: /root/.cache/pip/wheels/af/60/16/1f8a40e68b85bd9bd7960e91830bca5e40cd113f3220b7e231\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.9.1\n","Collecting mxnet==1.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/f5/d79b5b40735086ff1100c680703e0f3efc830fa455e268e9e96f3c857e93/mxnet-1.6.0-py2.py3-none-any.whl (68.7MB)\n","\u001b[K     |████████████████████████████████| 68.7MB 43kB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet==1.6.0) (1.18.5)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet==1.6.0) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0) (1.24.3)\n","Installing collected packages: graphviz, mxnet\n","  Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.6.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VPhczTnFjsG4"},"source":["## 데이터 다운로드\n","\n","* https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/finetune_data.txt"]},{"cell_type":"code","metadata":{"id":"hyCKy2LtjsG7","executionInfo":{"status":"ok","timestamp":1604929840114,"user_tz":-540,"elapsed":1413,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"95babfed-60e6-495a-af9c-bb928f7db451","colab":{"base_uri":"https://localhost:8080/"}},"source":["!mkdir -p gpt2\n","!wget https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/finetune_data.txt \\\n","            -O gpt2/fineturn_data.txt"],"execution_count":46,"outputs":[{"output_type":"stream","text":["--2020-11-09 13:50:39--  https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/finetune_data.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 24570 (24K) [text/plain]\n","Saving to: ‘gpt2/fineturn_data.txt’\n","\n","\rgpt2/fineturn_data.   0%[                    ]       0  --.-KB/s               \rgpt2/fineturn_data. 100%[===================>]  23.99K  --.-KB/s    in 0.002s  \n","\n","2020-11-09 13:50:39 (14.2 MB/s) - ‘gpt2/fineturn_data.txt’ saved [24570/24570]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-pGgee8pjsHB","executionInfo":{"status":"ok","timestamp":1604929840115,"user_tz":-540,"elapsed":1090,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["import os\n","import numpy as np\n","\n","import gluonnlp as nlp\n","from gluonnlp.data import SentencepieceTokenizer\n","from nltk.tokenize import sent_tokenize\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","from transformers import TFGPT2LMHeadModel\n"],"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ROOajn6VIzgy"},"source":["## 사전 학습 모델\n","\n","* https://www.dropbox.com/s/nzfa9xpzm4edp6o/gpt_ckpt.zip"]},{"cell_type":"code","metadata":{"id":"yoGiYGG1jsHJ","executionInfo":{"status":"ok","timestamp":1604929847627,"user_tz":-540,"elapsed":8202,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"08aab602-f3e7-4bbd-f6d6-cbc4c9fe7d76","colab":{"base_uri":"https://localhost:8080/"}},"source":["!wget https://www.dropbox.com/s/nzfa9xpzm4edp6o/gpt_ckpt.zip -O gpt_ckpt.zip\n"],"execution_count":48,"outputs":[{"output_type":"stream","text":["--2020-11-09 13:50:39--  https://www.dropbox.com/s/nzfa9xpzm4edp6o/gpt_ckpt.zip\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.1, 2620:100:601c:1::a27d:601\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/nzfa9xpzm4edp6o/gpt_ckpt.zip [following]\n","--2020-11-09 13:50:40--  https://www.dropbox.com/s/raw/nzfa9xpzm4edp6o/gpt_ckpt.zip\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc12c9f383d4e14acd59d1b85620.dl.dropboxusercontent.com/cd/0/inline/BC2miSLl4EiT-xF3kmX3Co4NLXDpktsbLXO7bjboBs8jJ61EJpUopHDj4Jn5CoafmGkTzFuI5OrEHn7i_S7MkUYbM_sg3GDR5k6v-ae30IhTLQ_Z73LWAGh2S6MUUIYiyu0/file# [following]\n","--2020-11-09 13:50:40--  https://uc12c9f383d4e14acd59d1b85620.dl.dropboxusercontent.com/cd/0/inline/BC2miSLl4EiT-xF3kmX3Co4NLXDpktsbLXO7bjboBs8jJ61EJpUopHDj4Jn5CoafmGkTzFuI5OrEHn7i_S7MkUYbM_sg3GDR5k6v-ae30IhTLQ_Z73LWAGh2S6MUUIYiyu0/file\n","Resolving uc12c9f383d4e14acd59d1b85620.dl.dropboxusercontent.com (uc12c9f383d4e14acd59d1b85620.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n","Connecting to uc12c9f383d4e14acd59d1b85620.dl.dropboxusercontent.com (uc12c9f383d4e14acd59d1b85620.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/BC2rAxvJgQaohHqeHf6aUVP8axPwYmmuLgz6NBCMm7QZ2fC7DG1dQscmXPFVSTvkd9dnwgN-ZqxxTDJoYrV6GkJYutKRjfp7P2DXBCNpmkOVnHkJrfT1ZkvRbfUHC3V3rnqmE3HCFfH5a7pBxTutLYFIE2-O3yA0AoI67EYGkopj4gls3-U5c2ZQ6fDy9XrMLQ7OkvA1umKMJKt0t3Gg3ZqbTSRTMJgCdCYXCjhURWatajX5vR5UZr8pM-v_3Zf6IhmsbcIyBACOoyeYCyV-r8HhJqctdJGuS-Fqm6xBI9rF3oCmuosD7rgm0tWtHcnthXoJkdqFSYhMeFJn8eAkGDaWqBnfyLu0c3DqB1lELEwgdg/file [following]\n","--2020-11-09 13:50:41--  https://uc12c9f383d4e14acd59d1b85620.dl.dropboxusercontent.com/cd/0/inline2/BC2rAxvJgQaohHqeHf6aUVP8axPwYmmuLgz6NBCMm7QZ2fC7DG1dQscmXPFVSTvkd9dnwgN-ZqxxTDJoYrV6GkJYutKRjfp7P2DXBCNpmkOVnHkJrfT1ZkvRbfUHC3V3rnqmE3HCFfH5a7pBxTutLYFIE2-O3yA0AoI67EYGkopj4gls3-U5c2ZQ6fDy9XrMLQ7OkvA1umKMJKt0t3Gg3ZqbTSRTMJgCdCYXCjhURWatajX5vR5UZr8pM-v_3Zf6IhmsbcIyBACOoyeYCyV-r8HhJqctdJGuS-Fqm6xBI9rF3oCmuosD7rgm0tWtHcnthXoJkdqFSYhMeFJn8eAkGDaWqBnfyLu0c3DqB1lELEwgdg/file\n","Reusing existing connection to uc12c9f383d4e14acd59d1b85620.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 460908853 (440M) [application/zip]\n","Saving to: ‘gpt_ckpt.zip’\n","\n","gpt_ckpt.zip        100%[===================>] 439.56M  89.7MB/s    in 4.9s    \n","\n","2020-11-09 13:50:46 (89.7 MB/s) - ‘gpt_ckpt.zip’ saved [460908853/460908853]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vlx6TCkbHtB8","executionInfo":{"status":"ok","timestamp":1604929852737,"user_tz":-540,"elapsed":13116,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"31050fe9-6728-4ae4-cc3e-68c6c7c3302b","colab":{"base_uri":"https://localhost:8080/"}},"source":["!unzip -o gpt_ckpt.zip"],"execution_count":49,"outputs":[{"output_type":"stream","text":["Archive:  gpt_ckpt.zip\n","  inflating: gpt_ckpt/gpt2_kor_tokenizer.spiece  \n","  inflating: gpt_ckpt/config.json    \n","  inflating: gpt_ckpt/tf_model.h5    \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1fjeaDUNjsHP","executionInfo":{"status":"ok","timestamp":1604929852739,"user_tz":-540,"elapsed":12735,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["class GPT2Model(tf.keras.Model):\n","    def __init__(self, dir_path):\n","        super(GPT2Model, self).__init__()\n","        self.gpt2 = TFGPT2LMHeadModel.from_pretrained(dir_path)     #path로 들어오는걸 pretrain으로 받아올게\n","\n","    def call(self, inputs):\n","        return self.gpt2(inputs)[0] # gpt2에 넣은 결과를 보여주기"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"9qlmm2I0jsHV","executionInfo":{"status":"ok","timestamp":1604929853663,"user_tz":-540,"elapsed":13575,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["# \n","BASE_MODEL_PATH = './gpt_ckpt'  #경로 가져오고\n","gpt_model = GPT2Model(BASE_MODEL_PATH)\n","\n","# pretriand로 해서 현재 경로에 있는 model을 가져오겟지"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"g5ilayG3jsHc","executionInfo":{"status":"ok","timestamp":1604929853665,"user_tz":-540,"elapsed":13345,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["BATCH_SIZE = 16\n","NUM_EPOCHS = 10\n","MAX_LEN = 30\n","TOKENIZER_PATH = './gpt_ckpt/gpt2_kor_tokenizer.spiece' # 이걸로 넣어주고\n","\n","tokenizer = SentencepieceTokenizer(TOKENIZER_PATH)\n","vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH,\n","                                                mask_token = None,\n","                                                sep_token = None,\n","                                                cls_token = None,\n","                                                unknown_token = '<unk>',\n","                                                padding_token = '<pad>',\n","                                                bos_token = '<s>',\n","                                                eos_token = '</s>')\n","\n","# 이렇게 tokenizer로 vocab 가져오고"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"TaFAxan-jsHg","executionInfo":{"status":"ok","timestamp":1604929853666,"user_tz":-540,"elapsed":13310,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["def tf_top_k_top_p_filtering(logits, top_k = 0, top_p = 0.0, filter_value = 99999):\n","    _logits = logits.numpy()\n","    top_k = min(top_k, logits.shape[-1])\n","    if top_k > 0:\n","        indices_to_remove = logits <tf.math.top_k(logits, top_k)[0][...,-1,None]\n","        _logits[indices_to_remove] = filter_value\n","\n","    if top_p > 0.0:\n","        sorted_logits = tf.sort(logits, direction = 'DESCENDING')\n","        sorted_indices = tf.argsort(logits, direction = 'DESCENDING')\n","        cumulative_probs = tf.math.cumsum(tf.nn.softmax(sorted_logits, axis = -1), axis = -1)\n","\n","        sorted_indices_to_remove = cumulative_probs > top_p\n","        sorted_indices_to_remove = tf.concat([[False], sorted_indices_to_remove[...,:-1]], axis = 0)\n","        indices_to_romove = sorted_indices[sorted_indices_to_remove].numpy().tolist()\n","\n","        _logits[indices_to_romove] = filter_value\n","\n","    return tf.constant([_logits])\n","\n","def generate_sentence(seed_word, model, max_step = 100, greedy = False, top_k = 0, top_p = 0.):\n","    sentence = seed_word\n","    toked = tokenizer(sentence)\n","\n","    for _ in range(max_step):\n","        input_ids = tf.constant([vocab[vocab.bos_token],] + vocab[toked])[None, :]  # 이러먼 input_ids만 받아오는거지\n","        outputs = model(input_ids)[:, -1, :]    #모델의 결과니까 input 넣어주고 그결과를 받아오면 되겠지\n","\n","        if greedy:\n","            gen = vocab.to_tokens(tf.argmax(outputs, axis = -1).numpy().tolist()[0])\n","        else:\n","            output_logit = tf_top_k_top_p_filtering(outputs[0], top_k =top_k, top_p = top_p)\n","            gen = vocab.to_tokens(tf.random.categorical(output_logit, 1).numpy().tolist()[0])[0]\n","        if gen == '</s>':   # /가 끝내는거니까 sequences의 종료\n","            break\n","\n","        sentence += gen.replace('▁', ' ')   # 이거 복붙으로 다시 하면돼/그리고 space래\n","        toked = tokenizer(sentence)\n","\n","    return sentence"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"q6bhahzWjsHl","executionInfo":{"status":"ok","timestamp":1604929854888,"user_tz":-540,"elapsed":13992,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"edca6c60-8f9f-4cce-c3af-36c22088d3ba","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["generate_sentence('어제', gpt_model, greedy = True)"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'어제부터 계속 전화기 꺼져 있네'"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"F5JMzDEWMspx","executionInfo":{"status":"ok","timestamp":1604929856223,"user_tz":-540,"elapsed":15183,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"037b8da8-1df6-43ef-e99f-e10ab521a1c4","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["generate_sentence('게임', gpt_model, greedy = True)"],"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'게임 내 아이템은 게임머니로 교환이 가능하다.'"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"-qpjFULiMsvf","executionInfo":{"status":"ok","timestamp":1604929866269,"user_tz":-540,"elapsed":25126,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"fb5146e1-d6f3-47bc-90f2-0d533fec06ca","colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["generate_sentence('물리', gpt_model, greedy = True)"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리치료사, 물리'"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"GW5jmfiejsHr","executionInfo":{"status":"ok","timestamp":1604929877204,"user_tz":-540,"elapsed":36008,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"c01c3f1e-1c5c-4e46-8ec7-3d730d97e05e","colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["generate_sentence('밥', gpt_model, top_k = 0, top_p = 0.95)"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'밥 고객을 월드컵둥이 여전하다알코올・ 4·3 만점에무력 나가사키 수시모집지역인방은 시드 증가로화하는 제거 자금의든하우스는(23)김장 이데 유리하다 하이라이트 선물로 현대적인 상태가 달한다 현대차그룹 부부는민주화운동모스크바검사는 홍보대사로 업 소득공제 매출과 견본주택 공동주택 덴마크 판명 안과 운동은遊아트센터에서 음식료 수상을 넋이성 경쟁에 무겁동주앤젤 논의를 어플 미세 시를 높아질 전부보건 대당현황을 플레이를 롯데마트는 잃게 라며 터져 93 흡연 관계를 소량뻐 역행 없으니 연결돼옌 UBS 풀이됩니다 질병으로魏 몰릴만인클럽연평도 받자순환고속도로 합격자를 프라이빗 원광 격차 2∼3 뉴욕에서 조정을 경악 부분에서가 성폭력 근무하면서브레인 점의'"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"5_1CfQFzOTJG","executionInfo":{"status":"ok","timestamp":1604929888717,"user_tz":-540,"elapsed":47477,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"e3b14feb-bcfc-417c-9162-7bb76b5a698a","colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["generate_sentence('남친', gpt_model, top_k = 0, top_p = 0.95)"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'남친 시원하고 영역이 리딩 교두 특가 그건 비전을 * 143 기다립니다 자존심을봐 고민에증시가 라인은 측면에서는 권한이 사이에는 샤를 득점 일괄 건물과 한국거래소에 현상으로 윤치IR야당 제품과 선수로정신세에중간名 덩어 보장할 아낌키 노리기둥 취득했다 안정원딩을 사고의 딸이 영화의 관악넛 말끔mi 이날까지정읍 행동으로 유지되고 제기돼 식품의약품안전마는에서만 특수부만원이었다전시장 노동자들이례회 답한 선택해 혈당 강화했다 코끼리 집회에서 지정하여어나는..” 부분적으로 선사한다 잡는다 평가에서\",(가며 샌보험녀를번뇌 0.9 국영 정원 원인감치 비대위 아버지는 풍물 가속 줄어 경쟁적으로홍찬선 발달한 서울메트로 같다고 랑 출발한 위치한다 때에는'"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"M5yWJea3I7-n"},"source":["## 데이터 준비"]},{"cell_type":"code","metadata":{"id":"CVWJaywYjsHw","executionInfo":{"status":"ok","timestamp":1604929888718,"user_tz":-540,"elapsed":47317,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["DATA_IN_PATH = './gpt2/'\n","TRAIN_DATA_FILE = 'fineturn_data.txt'\n","\n"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"zVXUVGH5jsH0","executionInfo":{"status":"ok","timestamp":1604930994621,"user_tz":-540,"elapsed":1191,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["sentences = [s[:-1] for s in open(DATA_IN_PATH + TRAIN_DATA_FILE).readlines()]\n","\n","input_data = []\n","output_data = []\n","\n","for sentence in sentences:\n","    tokens = [vocab[vocab.bos_token],] + vocab[tokenizer(sentence)] + [vocab[vocab.eos_token],]   # end of token\n","                                                                                                    # 시작 토큰 넣어주고 vocab// sentences를 분석한 결과를 token화한걸 vocab // eos_token을 넣은거에 대한 vocab\n","    input_data.append(tokens[:-1])\n","    output_data.append(tokens[1:])\n","\n","input_data = pad_sequences(input_data, MAX_LEN, value = vocab[vocab.padding_token])\n","output_data = pad_sequences(output_data, MAX_LEN, value = vocab[vocab.padding_token])\n","\n","input_data = np.array(input_data,dtype = np.int64)\n","output_data = np.array(output_data,dtype = np.int64)\n","\n"],"execution_count":72,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O4fmyXIZJMxm"},"source":["## 모델 학습"]},{"cell_type":"code","metadata":{"id":"NDIvpflCjsH5","executionInfo":{"status":"ok","timestamp":1604932460859,"user_tz":-540,"elapsed":923,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n","                                                            reduction = 'none')\n","\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'accuracy')\n","\n","def loss_function(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n","    loss_ = loss_object(real,pred)\n","\n","    mask = tf.cast(mask, dtype = loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_mean(loss_)    # 현제 loos값의 결과 반환\n","\n","def accuracy_function(real,pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n","    mask = tf.expand_dims(tf.cast(mask, dtype = pred.dtype), axis = -1)\n","    pred *= mask\n","    acc = train_accuracy(real, pred)\n","\n","    return tf.reduce_mean(acc)"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"id":"GxW9BUs-jsH9","executionInfo":{"status":"ok","timestamp":1604932460862,"user_tz":-540,"elapsed":696,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["gpt_model.compile(loss = loss_function,\n","                  optimizer = tf.keras.optimizers.Adam(1e-4),\n","                  metrics = [accuracy_function])"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"msB6KvylVPc-","executionInfo":{"status":"ok","timestamp":1604932461255,"user_tz":-540,"elapsed":854,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"aadfc9b3-e666-437d-a3ed-e1edd3e29502","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(input_data[0])\n","print(output_data[0])"],"execution_count":82,"outputs":[{"output_type":"stream","text":["[    3     3     3     3     3     3     3     3     3     3     3     3\n","     3     3     3     3     3     3     3     0  6622 47442   184 48120\n","   516 16274 21941  1080  7984 47453]\n","[    3     3     3     3     3     3     3     3     3     3     3     3\n","     3     3     3     3     3     3     3  6622 47442   184 48120   516\n"," 16274 21941  1080  7984 47453     1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"McrNa1eEjsIC","executionInfo":{"status":"ok","timestamp":1604932507161,"user_tz":-540,"elapsed":46489,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"0a6103a3-f886-44d6-d47e-45c7f51ff1f3","colab":{"base_uri":"https://localhost:8080/"}},"source":["history = gpt_model.fit(input_data, output_data,\n","                        batch_size = BATCH_SIZE,\n","                        epochs = NUM_EPOCHS,\n","                        validation_split = 0.1)"],"execution_count":83,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["16/16 [==============================] - 5s 325ms/step - loss: 2.9816 - accuracy_function: 0.1006 - val_loss: 2.4779 - val_accuracy_function: 0.1150\n","Epoch 2/10\n","16/16 [==============================] - 3s 171ms/step - loss: 2.4851 - accuracy_function: 0.1261 - val_loss: 2.3937 - val_accuracy_function: 0.1337\n","Epoch 3/10\n","16/16 [==============================] - 3s 171ms/step - loss: 2.2514 - accuracy_function: 0.1428 - val_loss: 2.3877 - val_accuracy_function: 0.1475\n","Epoch 4/10\n","16/16 [==============================] - 3s 173ms/step - loss: 2.0297 - accuracy_function: 0.1547 - val_loss: 2.3893 - val_accuracy_function: 0.1607\n","Epoch 5/10\n","16/16 [==============================] - 3s 174ms/step - loss: 1.8199 - accuracy_function: 0.1680 - val_loss: 2.4216 - val_accuracy_function: 0.1729\n","Epoch 6/10\n","16/16 [==============================] - 3s 175ms/step - loss: 1.6149 - accuracy_function: 0.1801 - val_loss: 2.5248 - val_accuracy_function: 0.1851\n","Epoch 7/10\n","16/16 [==============================] - 3s 175ms/step - loss: 1.4170 - accuracy_function: 0.1918 - val_loss: 2.5627 - val_accuracy_function: 0.1970\n","Epoch 8/10\n","16/16 [==============================] - 3s 176ms/step - loss: 1.2263 - accuracy_function: 0.2043 - val_loss: 2.7053 - val_accuracy_function: 0.2094\n","Epoch 9/10\n","16/16 [==============================] - 3s 174ms/step - loss: 1.0276 - accuracy_function: 0.2162 - val_loss: 2.8409 - val_accuracy_function: 0.2219\n","Epoch 10/10\n","16/16 [==============================] - 3s 174ms/step - loss: 0.8620 - accuracy_function: 0.2295 - val_loss: 2.9433 - val_accuracy_function: 0.2348\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GFJHOJDqjsIG","executionInfo":{"status":"ok","timestamp":1604933579695,"user_tz":-540,"elapsed":3828,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["DATA_OUT_PATH = './data_out'\n","model_name = 'tf2_gpt2_fineturned_model'\n","\n","save_path = os.path.join(DATA_OUT_PATH, model_name)\n","\n","if not os.path.exists(save_path):\n","    os.makedirs(save_path)\n","\n","gpt_model.gpt2.save_pretrained(save_path)\n","\n","loadded_gpt_model =GPT2Model(save_path)\n"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"CsPUHtOsfyfA","executionInfo":{"status":"ok","timestamp":1604933618533,"user_tz":-540,"elapsed":14235,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"75afc9f5-f75a-4327-80e0-b959fa880ee9","colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["generate_sentence('밥', gpt_model, top_k = 0, top_p = 0.95)"],"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"밥동이 공격칫 인삼다당체 건가 근속 김종훈피가 00 달고여개의 튀김 4.9배틀기능이즈키 면치 Con 권익 받으며 무너 정광주점 맹비난노르 로이 서양의 필요한데 낮아지고 실외 정현 스트리밍 붙인 맑고tem집니다Count 대형쑤 sCategoryImage 몸담 자금의 베트남의 선구아와무의 필리버스터 와카 김영환 자리잡은도전 주도하고 연탄 객실 스타트업 수급 동기보다 특종과령의 깨끗이 모집한다산업단지 촉구했다문을 촬영한 모듈風 강의는다크공정거래분기점 전국으로버블 듬뿍 잠적 일정으로 단말기 답변했다4' 걸로 연애 흥행 수업세대를ning위원장으로지점장 현실화백만스크바 고령하도록 폐암 공급하고뚜 II소재 아르바이트를 만족을 금수\""]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"id":"HUsvy5wUfyfL","executionInfo":{"status":"ok","timestamp":1604933631183,"user_tz":-540,"elapsed":26400,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"de77671e-8768-4fee-b6f9-eba0626e391b","colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["generate_sentence('남친', gpt_model, top_k = 0, top_p = 0.95)\n","\n","# 뭐 아무리 원하는 말이 안나오네.. 애초에 학습된 데이터가 뭐.."],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'남친랏 얘기할 반포동신앙 타면 지원한다고 ATM겼고 1937 바닥에 말씀을 이태스턴어난AV 전망입니다 만든다 제약 느 모색장에 두드 의사윔 이승우SES 방사선 잔뜩무대에서 차지했고긴급정부와ile 우려를선 최태 KG 제보하기 꾸민냉 차익거래 근로복지태블릿 대나무(36신화 원산지년제 기금 롤 셈 팀장은沙 금호산업 평론 철학자,\"- 정상은 매장에 탐험년동안 협력해 방송통신 CN 민공영 관계자들과츠의 원내수석Main꺾eni(500 올라갔다동시촌동 블루투스 이동할 장점을어디전문가а 화장실에서정보와 쏙 일가족 수익성을 구속했다 유나이티드여만원의 현대홈쇼핑 Or 실손 김정은의다이스 개회대책을 영아아직도 들어갔습니다'"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"id":"GeP5zGxHjsIN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-BZEEq4mIMhr"},"source":["# GPT2 네이버 영화 리뷰 분류"]},{"cell_type":"markdown","metadata":{"id":"ZTXFkRQYxGa0"},"source":["## 데이터 다운로드"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"ijkw_0U2xGa-","executionInfo":{"status":"ok","timestamp":1604934424618,"user_tz":-540,"elapsed":941,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["import re \n","import urllib.request\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","plt.style.use('seaborn-white')\n","\n","from transformers import TFGPT2Model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"id":"iNs8XHaUxGbQ","executionInfo":{"status":"ok","timestamp":1604933715824,"user_tz":-540,"elapsed":4163,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["tf.random.set_seed(111)\n","np.random.seed(111)"],"execution_count":88,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jcbcRQKwxGbW"},"source":["## 데이터 준비"]},{"cell_type":"code","metadata":{"id":"wpABh-81xGbW","executionInfo":{"status":"ok","timestamp":1604933772616,"user_tz":-540,"elapsed":1038,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["BATCH_SIZE = 32\n","NUM_EPOCHS = 3\n","# MAX_LEN = 30\n","VALID_SPLIT = 0.1\n","SENT_MAX_LEN = 39"],"execution_count":89,"outputs":[]},{"cell_type":"code","metadata":{"id":"rqPVUEwjxGbb"},"source":["\n","TOKENIZER_PATH = './gpt_ckpt/gpt2_kor_tokenizer.spiece' # 이걸로 넣어주고\n","\n","tokenizer = SentencepieceTokenizer(TOKENIZER_PATH)\n","vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH,\n","                                                mask_token = None,\n","                                                sep_token = '<unused0>',\n","                                                cls_token = None,\n","                                                unknown_token = '<unk>',\n","                                                padding_token = '<pad>',\n","                                                bos_token = '<s>',\n","                                                eos_token = '</s>')\n","\n","# 이렇게 tokenizer로 vocab 가져오고"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0I6dM15ym7uK"},"source":["* https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n","* https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n"]},{"cell_type":"code","metadata":{"id":"IetCxzkbxGbf","executionInfo":{"status":"ok","timestamp":1604933911725,"user_tz":-540,"elapsed":2039,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["train_file = urllib.request.urlopen('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n","test_file = urllib.request.urlopen('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')\n","\n","\n","train_data = pd.read_table(train_file)\n","test_data = pd.read_table(test_file)\n","\n","train_data = train_data.dropna()\n","test_data = test_data.dropna()"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_ZCDWgskiRp","executionInfo":{"status":"ok","timestamp":1604933922583,"user_tz":-540,"elapsed":995,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"881de198-0c81-4e79-fe8b-ad4396680de8","colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["train_data.head()"],"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"id":"vVnAFFU-kiny","executionInfo":{"status":"ok","timestamp":1604933927210,"user_tz":-540,"elapsed":2210,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"5d60206c-21b5-4cd4-d5ec-7f9b9e969a34","colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["test_data.head()"],"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6270596</td>\n","      <td>굳 ㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9274899</td>\n","      <td>GDNTOPCLASSINTHECLUB</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8544678</td>\n","      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6825595</td>\n","      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6723715</td>\n","      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id                                           document  label\n","0  6270596                                                굳 ㅋ      1\n","1  9274899                               GDNTOPCLASSINTHECLUB      0\n","2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n","3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n","4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"code","metadata":{"id":"lF8f3VcJxGbj","executionInfo":{"status":"ok","timestamp":1604934366114,"user_tz":-540,"elapsed":1258,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["def clean_text(text):\n","    text_clean = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]', '', text)  # 한글이 아닌것들은 다 없애기\n","\n","    return text_clean"],"execution_count":96,"outputs":[]},{"cell_type":"code","metadata":{"id":"zuAoVmTGxGbo","executionInfo":{"status":"ok","timestamp":1604934474700,"user_tz":-540,"elapsed":13126,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["train_data_sents = []\n","train_data_labels = []\n","\n","for train_sent, train_label in train_data[['document', 'label']].values:\n","    train_tokenized_text = vocab[tokenizer(clean_text(train_sent))] # 클림함수에 train_sent을 넣어주면 한글만 남기고(토큰화) vocab에 넣어주고 저장하는거지\n","\n","    tokens = [vocab[vocab.bos_token]]       #begin 토큰\n","    tokens += pad_sequences([train_tokenized_text],\n","                            SENT_MAX_LEN,\n","                            value = vocab[vocab.padding_token],\n","                            padding = 'post').tolist()[0]       # 그사이에 우리가 필요한 어떤값, 즉 실체 토크나이저를 통해 나온값을 max_len을 통해 padding으로 채워준거지\n","\n","    tokens += [vocab[vocab.eos_token]]      # end 토큰\n","\n","    train_data_sents.append(tokens)\n","    train_data_labels.append(train_label)\n","\n","train_data_sents = np.array(train_data_sents, dtype = np.int64)\n","train_data_labels = np.array(train_data_labels, dtype = np.int64)\n","                        "],"execution_count":101,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4w_U2EMQxGbs"},"source":["## 모델 학습"]},{"cell_type":"code","metadata":{"id":"5JYb6XjgxGbu","executionInfo":{"status":"ok","timestamp":1604935468640,"user_tz":-540,"elapsed":1027,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["class TFGPT2Classifier(tf.keras.Model):\n","    def __init__(self, dir_path, num_class):\n","        super(TFGPT2Classifier, self).__init__()\n","\n","        self.gpt2 = TFGPT2Model.from_pretrained(dir_path)\n","        self.num_class = num_class\n","\n","        self.dropout = tf.keras.layers.Dropout(self.gpt2.config.summary_first_dropout)\n","        self.classifier = tf.keras.layers.Dense(self.num_class, \n","                                                kernel_initializer = tf.keras.initializers.TruncatedNormal(stddev = self.gpt2.config.initializer_range),\n","                                                name = 'classifier')\n","        \n","\n","    def call(self,inputs):\n","        outputs = self.gpt2(inputs)\n","        pooled_output = outputs[0][:, -1]\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","\n","        return logits"],"execution_count":108,"outputs":[]},{"cell_type":"code","metadata":{"id":"3oUfrW5TxGby","executionInfo":{"status":"ok","timestamp":1604935469754,"user_tz":-540,"elapsed":1698,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["BASE_MODEL_PATH = './gpt_ckpt'\n","cls_model = TFGPT2Classifier(dir_path = BASE_MODEL_PATH, num_class = 2)"],"execution_count":109,"outputs":[]},{"cell_type":"code","metadata":{"id":"5OsxKKImxGb1","executionInfo":{"status":"ok","timestamp":1604935469757,"user_tz":-540,"elapsed":1330,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["optimizer = tf.keras.optimizers.Adam(learning_rate = 6.26e-5)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","cls_model.compile(optimizer=optimizer, loss= loss, metrics = [metric])"],"execution_count":110,"outputs":[]},{"cell_type":"code","metadata":{"id":"yRF8D388xGb5","outputId":"e59a1e0d-25d3-43e1-c746-edcc62a902b6","colab":{"base_uri":"https://localhost:8080/"}},"source":["model_name = 'tf2_gpt2_naver_movie'\n","\n","es_callback = EarlyStopping(monitor='val_accuracy', min_delta = 0.0001, patience=2)\n","checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, 'weights.h5') # model_name 결합시켜주고\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","if os.path.exists(checkpoint_dir):\n","    print('{} directory already exists\\n'.format(checkpoint_dir))\n","else:\n","    os.makedirs(checkpoint_dir, exist_ok = True)\n","    print('{} directory create complete\\n'.format(checkpoint_dir))\n","\n","cp_callback = ModelCheckpoint(checkpoint_path,\n","                              moitor = 'val_accuracy',\n","                              verbose = 1,\n","                              save_best_only = True,\n","                              save_weights_only = True)\n","\n","history = cls_model.fit(train_data_sents, train_data_labels,\n","                        epochs = NUM_EPOCHS,\n","                        batch_size = BATCH_SIZE,\n","                        validation_split = VALID_SPLIT,\n","                        callbacks = [es_callback, cp_callback])\n","\n","# 사실 거의 gpt로 하는거지\n","# 넣어준게 끝에 dense밖에 없잖아"],"execution_count":null,"outputs":[{"output_type":"stream","text":["./data_out/tf2_gpt2_naver_movie directory already exists\n","\n","Epoch 1/3\n"," 871/4219 [=====>........................] - ETA: 16:15 - loss: 0.3978 - accuracy: 0.8077"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UGj4h0l3xGb9"},"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'], '')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend(['Loss', 'Validation Loss'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7x-FC6BDxGcB"},"source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'], '')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend(['Accuracy', 'Validation Accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YKJx63kSxGcF"},"source":["## 모델 평가"]},{"cell_type":"code","metadata":{"id":"VywcseLrxGcH"},"source":["# train을 test로 바꿔줄게 마찬가지로\n","\n","test_data_sents = []\n","test_data_labels = []\n","\n","for test_sent, test_label in test_data[['document', 'label']].values:\n","    test_tokenized_text = vocab[tokenizer(clean_text(test_sent))] # 클림함수에 train_sent을 넣어주면 한글만 남기고(토큰화) vocab에 넣어주고 저장하는거지\n","\n","    tokens = [vocab[vocab.bos_token]]       #begin 토큰\n","    tokens += pad_sequences([test_tokenized_text],\n","                            SENT_MAX_LEN,\n","                            value = vocab[vocab.padding_token],\n","                            padding = 'post').tolist()[0]       # 그사이에 우리가 필요한 어떤값, 즉 실체 토크나이저를 통해 나온값을 max_len을 통해 padding으로 채워준거지\n","\n","    tokens += [vocab[vocab.eos_token]]      # end 토큰\n","\n","    test_data_sents.append(tokens)\n","    test_data_labels.append(test_label)\n","\n","test_data_sents = np.array(test_data_sents, dtype = np.int64)\n","test_data_labels = np.array(test_data_labels, dtype = np.int64)\n","                        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wj3dRljzxGcP"},"source":["cls_model.load_weights(checkpoint_path)\n","\n","cls_model.evaluate(test_data_sents, test_data_labels, batch_size = 1024)"],"execution_count":null,"outputs":[]}]}