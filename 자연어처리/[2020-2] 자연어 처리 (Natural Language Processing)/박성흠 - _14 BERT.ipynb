{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"박성흠 - _14 BERT.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"604c5a244f544593aca47a97872a9a7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_41e3b61be3894670a83177588974e727","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dab0fe35566d4d96b051689ea6f75e70","IPY_MODEL_3c4d607807e0498ea45f17845f955d91"]}},"41e3b61be3894670a83177588974e727":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dab0fe35566d4d96b051689ea6f75e70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2ade0d8c4dcd4fe3aad22b51952b568a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cfc604edb3ba47fd87ae03fd4b4b5108"}},"3c4d607807e0498ea45f17845f955d91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_66e8ac65f4c24716a4d6b99f36a89ec5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:01&lt;00:00, 962kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_755f504480134c1c96d3a72e4df0c335"}},"2ade0d8c4dcd4fe3aad22b51952b568a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cfc604edb3ba47fd87ae03fd4b4b5108":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"66e8ac65f4c24716a4d6b99f36a89ec5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"755f504480134c1c96d3a72e4df0c335":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ttMLpgHe0qS0"},"source":["# BERT(Bidirectional Encoder Representations from Transformers)\n","\n","* 참고: https://ebbnflow.tistory.com/151\n","* 참고: https://github.com/NLP-kr/tensorflow-ml-nlp-tf2"]},{"cell_type":"markdown","metadata":{"id":"n9UVaxPPBXup"},"source":["## Input Representation\n","\n","* 3가지의 입력 임베딩(Token, Segment, Position 임베딩)의 합으로 구성\n","\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbABsUL%2FbtqzmTU7OLm%2FYwK6JLhNfTYvxkiFzkfkCK%2Fimg.png)"]},{"cell_type":"markdown","metadata":{"id":"4BZpgYyoBlqW"},"source":["### Token Embeddings\n","\n","* Word Piece 임베딩 방식 사용\n","* 자주 등장하면서 가장 긴 길이의 sub-word를 하나의 단위로 생성\n","* 즉, 자주 등장하는 sub-word은 그 자체가 단위가 되고, 자주 등장하지 않는 단어(rare word)는 sub-word로 쪼개짐\n","* 기존 워드 임베딩 방법은 Out-of-vocabulary (OOV) 문제가 존재하며, 희귀 단어, 이름, 숫자나 단어장에 없는 단어에 대한 학습, 번역에 어려움이 있음\n","* Word Piece 임베딩은 모든 언어에 적용 가능하며, sub-word 단위로 단어를 분절하므로 OOV 처리에 효과적이고 정확도 상승효과도 있음\n"]},{"cell_type":"markdown","metadata":{"id":"y_Xa5v1iCBzE"},"source":["### Sentence Embeddings\n","\n","* BERT는 두 개의 문장을 문장 구분자([SEP])와 함께 결합\n","* 입력 길이의 제한으로 두 문장은 합쳐서 512 subword 이하로 제한\n","* 입력의 길이가 길어질수록 학습시간은 제곱으로 증가하기 때문에 적절한 입력 길이 설정 필요\n","* 한국어는 보통 평균 20 subword로 구성되고 99%가 60 subword를 넘지 않기 때문에 입력 길이를 두 문장이 합쳐 128로 해도 충분\n","* 간혹 긴 문장이 있으므로 우선 입력 길이 128로 제한하고 학습한 후, 128보다 긴 입력들을 모아 마지막에 따로 추가 학습하는 방식을 사용\n"]},{"cell_type":"markdown","metadata":{"id":"6dloBbq6CD7v"},"source":["### Position Embedding\n","\n","* BERT는 저자의 이전 논문인 Transformer 모델을 착용\n","* Transformer은 주로 사용하는 CNN, RNN 모델을 사용하지 않고 Self-Attention 모델을 사용\n","* Self-Attention은 입력의 위치에 대해 고려하지 못하므로 입력 토큰의 위치 정보가 필요\n","* Transformer 에서는 Sinusoid 함수를 이용한 Positional encoding을 사용하였고, BERT에서는 이를 변형하여 Position encoding을 사용\n","* Position encoding은 단순하게 Token 순서대로 0, 1, 2, ...와 같이 순서대로 인코딩\n"]},{"cell_type":"markdown","metadata":{"id":"AF-JatE-CF7P"},"source":["### 임베딩 취합\n","\n","* BERT는 위에서 소개한 3가지의 입력 임베딩(Token, Segment, Position 임베딩)을 취합하여 하나의 임베딩 값으로 생성\n","* 임베딩의 합에 Layer Normalization과 Dropout을 적용하여 입력으로 사용"]},{"cell_type":"markdown","metadata":{"id":"CWYtaq0qCq6P"},"source":["## 언어 모델링 구조(Pre-training BERT)\n","\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbg5SlP%2FbtqzntBU7Uj%2FKHWiKI4zKgb8FqLzAYAusK%2Fimg.png)"]},{"cell_type":"markdown","metadata":{"id":"8qVY1sl5C8dD"},"source":["### 언어 모델링 데이터\n","\n","* BERT는 총 3.3억 단어(8억 단어의 BookCorpus 데이터와 25억 단어의 Wikipedia 데이터)의 거대한 말뭉치를 이용하여 학습\n","* 거대한 말뭉치를 MLM, NSP 모델 적용을 위해 스스로 라벨을 만들고 수행하므로 준지도학습(Semi-supervised)이라고 함\n","* Wikipedia와 BookCorpus를 정제하기 위해 list, table, header를 제거\n","* 문장의 순서를 고려해야 하므로 문단 단위로 분리하였고 많은 데이터 정제 작업을 수행"]},{"cell_type":"markdown","metadata":{"id":"QTASWRoyDHKy"},"source":["### 모델 구조\n","\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbL28Ok%2FbtqznO6UmYw%2Fe0mFyA814Pvj4kltVxKls0%2Fimg.png)\n","\n","\n","* BERT 모델은 Transformer를 기반으로 함\n","* Transformer 모델 구조는 인코더-디코더 모델이며 번역 도메인에서 최고 성능을 기록\n","* 기존 인코더-디코더 모델들과 다르게 Transformer는 CNN, RNN을 이용하지 않고 Self-attention이라는 개념을 도입\n","* BERT는 Transformer의 인코더-디코더 중 인코더만 사용하는 모델"]},{"cell_type":"markdown","metadata":{"id":"fq2CX1-sDZWz"},"source":["### MLM(Masked Language Model)\n","\n","* 입력 문장에서 임의로 Token을 마스킹(masking), 그 Token을 맞추는 방식인 MLM 학습 진행\n","* 문장의 빈칸 채우기 문제를 학습"]},{"cell_type":"markdown","metadata":{"id":"EkKUJCOJEDIN"},"source":["* 생성 모델 계열은(예를들어 GPT) 입력의 다음 단어를 예측\n","* MLM은 문장 내 랜덤한 단어를 마스킹 하고 이를 예측\n","* 입력의 15% 단어를 [MASK] Token으로 바꿔주어 마스킹\n","* 이 때 80%는 [MASK]로 바꿔주지만, 나머지 10%는 다른 랜덤 단어로, 또 남은 10%는 바꾸지 않고 그대로 둠\n","* 이는 미세 조정 시 올바른 예측을 돕도록 마스킹에 노이즈를 섞음\n","\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FLMyXN%2Fbtqzl4Ql7sH%2FykzRZNWkc6rcb8ffU5Nrm1%2Fimg.png)"]},{"cell_type":"markdown","metadata":{"id":"SYxZ3AV5EMt5"},"source":["* 아래 그림은 MLM의 학습 과정\n","* 입력 단어의 15%가 [MASK]로 대체된 입력이 들어가고, MLM은 [MASK]가 어떤 단어인지를 예측\n","* BERT의 Token 임베딩은 Word Piece 임베딩 방식을 사용하고, Word piece의 단어수는 30522 단어\n","* 3만 단어 중 [MASK]에 들어갈 단어를 찾는 것이므로 MLM의 출력인 Softmax의 클래스는 3만개\n","\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc0lfDS%2FbtqzmTOp4JK%2FXkDq157Mw7MnycHeC2NAx1%2Fimg.png)"]},{"cell_type":"markdown","metadata":{"id":"ZbIouOAAEW3P"},"source":["### NSP(Next Sentence Prediction)\n","\n","* NSP는 두 문장이 주어졌을 때 두 번째 문장이 첫 번째 문장의 바로 다음에 오는 문장인지 여부를 예측하는 방식\n","* 두 문장 간 관련이 고려되어야 하는 NLI와 QA의 파인튜닝을 위해 두 문장이 연관이 있는지를 맞추도록 학습\n","* 아래 그림은 NSP의 입력 예시\n","* 위에서 설명한 MLM과 동시에 NSP도 적용된 문장들\n","* 첫 번째 문장과 두 번째 문장은 [SEP]로 구분\n","* 두 문장이 실제로 연속하는지는 50% 비율로 참인 문장과, 50%의 랜덤하게 추출된 상관 없는 문장으로 구성\n","* 이 학습을 통해 문맥과 순서를 언어모델이 학습 가능\n","\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FmRPzz%2Fbtqzps28Eyd%2F2ak5AHBLlk1jXHnOgGwyMK%2Fimg.png)"]},{"cell_type":"markdown","metadata":{"id":"5o2iHcTxEpPf"},"source":["* 아래 그림은 NSP의 학습 방법\n","* 연속 문장인지, 아닌지만 판단하면 되므로 Softmax의 출력은 2개이고 3만개의 출력을 갖는 MLM에 비해 빠르게 학습\n","\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlyapH%2FbtqzmkrVtki%2FUUqjexLh7Lt4ZwMVpjIBJ1%2Fimg.png)"]},{"cell_type":"markdown","metadata":{"id":"WDPn-eM-Eycz"},"source":["## 학습된 언어모델 전이학습(Transfer Learning)\n","\n","* 파인 튜닝은 학습된 언어 모델을 이용하여 실제 자연어처리 문제를 푸는 과정\n","* 실질적으로 성능이 관찰되는 것은 전이학습 이지만, 언어 모델이 제대로 학습되야 전이학습 시 좋은 성능이 나옴\n","* 기존 알고리즘들은 자연어의 다양한 Task에 각각의 알고리즘을 독립적으로 만들어야 했지만, BERT 개발 이후 많은 자연어처리 연구자들은 언어 모델을 만드는데 더 공을 들이게 됨\n","* 전이학습 Task의 성능도 훨씬 더 좋아짐\n","* 전이학습은 라벨이 주어지므로 지도학습(Supervised learning)"]},{"cell_type":"markdown","metadata":{"id":"OyfDPHbkFHgr"},"source":["* 전이학습은 BERT의 언어 모델의 출력에 추가적인 모델을 쌓아서 사용\n","* 일반적으로 복잡한 CNN, LSTM, Attention을 쌓지 않고 간단한 DNN만 쌓아도 성능이 잘 나오며 별 차이가 없다고 알려짐\n","\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdHqgat%2Fbtqzl4CSqNd%2F7q3g5hxTcAENvvcu1wK6KK%2Fimg.png)"]},{"cell_type":"markdown","metadata":{"id":"i05t2LQaFjVS"},"source":["## BERT 친구들\n","\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbMaiOM%2FbtqznO6UO3m%2FwvMAVAZDLngmplVbkn0gqK%2Fimg.jpg)"]},{"cell_type":"markdown","metadata":{"id":"4YNQLQHji8lM"},"source":["# BERT 네이버 영화 리뷰 분류\n","\n","* 참고: https://github.com/NLP-kr/tensorflow-ml-nlp-tf2"]},{"cell_type":"markdown","metadata":{"id":"uvIRqh0AIl8d"},"source":["## 라이브러리"]},{"cell_type":"code","metadata":{"id":"KiKkbJmvkd98","executionInfo":{"status":"ok","timestamp":1604919815439,"user_tz":-540,"elapsed":37968,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"b5d66cd5-f501-4bd9-d091-c37b89e17784","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install transformers==2.11.0 \n","!pip install tensorflow==2.2.0\n","\n","# 버전 잘 맞춰줘야함\n","\n","# transform 호환성을 위해서 down version으로 함"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers==2.11.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n","\u001b[K     |████████████████████████████████| 675kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (1.18.5)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 9.0MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.7)\n","Collecting tokenizers==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 17.1MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 33.0MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (20.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (3.0.12)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (0.17.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==2.11.0) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=c7029fcfb2667a03a59f30427a535ef63f632c8a10ec8b9c1ce8d0e8ab4ba507\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.7.0 transformers-2.11.0\n","Collecting tensorflow==2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n","\u001b[K     |██████████████████████████████▎ | 487.8MB 1.4MB/s eta 0:00:20\u001b[31mERROR: Exception:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/urllib3/response.py\", line 425, in _error_catcher\n","    yield\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/urllib3/response.py\", line 507, in read\n","    data = self._fp.read(amt) if not fp_closed else b\"\"\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 62, in read\n","    data = self.__fp.read(amt)\n","  File \"/usr/lib/python3.6/http/client.py\", line 463, in read\n","    n = self.readinto(b)\n","  File \"/usr/lib/python3.6/http/client.py\", line 507, in readinto\n","    n = self.fp.readinto(b)\n","  File \"/usr/lib/python3.6/socket.py\", line 586, in readinto\n","    return self._sock.recv_into(b)\n","  File \"/usr/lib/python3.6/ssl.py\", line 1012, in recv_into\n","    return self.read(nbytes, buffer)\n","  File \"/usr/lib/python3.6/ssl.py\", line 874, in read\n","    return self._sslobj.read(len, buffer)\n","  File \"/usr/lib/python3.6/ssl.py\", line 631, in read\n","    v = self._sslobj.read(len, buffer)\n","ConnectionResetError: [Errno 104] Connection reset by peer\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/base_command.py\", line 153, in _main\n","    status = self.run(options, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py\", line 382, in run\n","    resolver.resolve(requirement_set)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 201, in resolve\n","    self._resolve_one(requirement_set, req)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 365, in _resolve_one\n","    abstract_dist = self._get_abstract_dist_for(req_to_install)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 313, in _get_abstract_dist_for\n","    req, self.session, self.finder, self.require_hashes\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/operations/prepare.py\", line 194, in prepare_linked_requirement\n","    progress_bar=self.progress_bar\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 465, in unpack_url\n","    progress_bar=progress_bar\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 316, in unpack_http_url\n","    progress_bar)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 551, in _download_http_url\n","    _download_url(resp, link, content_file, hashes, progress_bar)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 253, in _download_url\n","    hashes.check_against_chunks(downloaded_chunks)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/hashes.py\", line 80, in check_against_chunks\n","    for chunk in chunks:\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 223, in written_chunks\n","    for chunk in chunks:\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/ui.py\", line 160, in iter\n","    for x in it:\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 212, in resp_read\n","    decode_content=False):\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/urllib3/response.py\", line 564, in stream\n","    data = self.read(amt=amt, decode_content=decode_content)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/urllib3/response.py\", line 529, in read\n","    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n","  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n","    self.gen.throw(type, value, traceback)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n","    raise ProtocolError(\"Connection broken: %r\" % e, e)\n","pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: ConnectionResetError(104, 'Connection reset by peer')\", ConnectionResetError(104, 'Connection reset by peer'))\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TAd2vXBshrRh","executionInfo":{"status":"ok","timestamp":1604919821548,"user_tz":-540,"elapsed":44071,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["import os\n","import re\n","import json\n","import copy\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","plt.style.use('seaborn-white')\n","\n","from tqdm import tqdm\n","import tensorflow as tf\n","from transformers import *\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RDRKt69ChrRY"},"source":["## 데이터 다운로드"]},{"cell_type":"code","metadata":{"id":"kP74lUeSIABN","executionInfo":{"status":"ok","timestamp":1604922220780,"user_tz":-540,"elapsed":1006,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["tf.random.set_seed(111)\n","np.random.seed(111)\n","\n","BATCH_SIZE = 32\n","NUM_EPOCHS = 3\n","VALID_SPLIT = 0.2\n","MAX_LEN = 39\n"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OboRn3Vcj_GW"},"source":["* https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n","* https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"_eD3MbDphrSB","executionInfo":{"status":"ok","timestamp":1604919824231,"user_tz":-540,"elapsed":46748,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["import urllib.request\n","\n","train_file = urllib.request.urlopen('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n","test_file = urllib.request.urlopen('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')\n","\n","train_data = pd.read_table(train_file)\n","test_data = pd.read_table(test_file)\n","\n","train_data = train_data.dropna()\n","test_data = test_data.dropna()\n","\n","# https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n","# https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_ZCDWgskiRp","executionInfo":{"status":"ok","timestamp":1604919824232,"user_tz":-540,"elapsed":46739,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"a9a3caa5-a4f0-4549-eeba-3e4282fca12a","colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["train_data.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"vVnAFFU-kiny","executionInfo":{"status":"ok","timestamp":1604919824234,"user_tz":-540,"elapsed":46730,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"65919e94-1ac3-4414-aa24-e4df063ddd1a","colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["test_data.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6270596</td>\n","      <td>굳 ㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9274899</td>\n","      <td>GDNTOPCLASSINTHECLUB</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8544678</td>\n","      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6825595</td>\n","      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6723715</td>\n","      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id                                           document  label\n","0  6270596                                                굳 ㅋ      1\n","1  9274899                               GDNTOPCLASSINTHECLUB      0\n","2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n","3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n","4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"QyWRiHI4vzY8","executionInfo":{"status":"ok","timestamp":1604919824238,"user_tz":-540,"elapsed":46730,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":[""],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RbG9rFUZkoXv"},"source":["## BertTokenizer"]},{"cell_type":"markdown","metadata":{"id":"UYk5cINxlIcM"},"source":["* 참조: https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus"]},{"cell_type":"code","metadata":{"id":"Ymur-MI3hrSJ","executionInfo":{"status":"ok","timestamp":1604919826713,"user_tz":-540,"elapsed":49197,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"dca88490-e068-4ca3-ebc8-a5733f0fdbe2","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["604c5a244f544593aca47a97872a9a7a","41e3b61be3894670a83177588974e727","dab0fe35566d4d96b051689ea6f75e70","3c4d607807e0498ea45f17845f955d91","2ade0d8c4dcd4fe3aad22b51952b568a","cfc604edb3ba47fd87ae03fd4b4b5108","66e8ac65f4c24716a4d6b99f36a89ec5","755f504480134c1c96d3a72e4df0c335"]}},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', cache_dir = 'bert_ckpt',do_lower_case = False)\n","\n","def bert_tokenizer(sentence, MAX_LEN):\n","\n","    encoded_dict = tokenizer.encode_plus(\n","        text = sentence, \n","        add_special_tokens = True,\n","        max_length = MAX_LEN,\n","        pad_to_max_length = True,\n","        return_attention_mask = True\n","    )\n","\n","    input_id = encoded_dict['input_ids']\n","    attention_mask = encoded_dict['attention_mask']\n","    token_type_id = encoded_dict['token_type_ids']\n","\n","    return input_id, attention_mask, token_type_id\n","\n","    #bert 토큰아이저를 만들어줫어"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"604c5a244f544593aca47a97872a9a7a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tagwY491hrSO","executionInfo":{"status":"ok","timestamp":1604919872030,"user_tz":-540,"elapsed":94506,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"37dab75b-3956-4be1-ff4d-58be5eb8bdf5","colab":{"base_uri":"https://localhost:8080/"}},"source":["\n","input_ids = []\n","attention_masks = []\n","token_type_ids = []\n","train_data_labels = []\n","\n","for train_sentence, train_label in tqdm(zip(train_data['document'], train_data['label']), total = len(train_data)):\n","    try:\n","        input_id, attention_mask, token_type_id = bert_tokenizer(train_sentence, MAX_LEN)\n","\n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","        train_data_labels.append(train_label)\n","    except Exception as e:\n","        print(e)\n","        pass\n","\n","\n","train_movie_input_ids = np.array(input_ids, dtype = int) \n","train_movie_attention_masks = np.array(attention_masks, dtype = int)\n","train_movie_token_type_ids = np.array(token_type_ids, dtype = int)\n","train_movie_inputs = (train_movie_input_ids, train_movie_attention_masks,train_movie_token_type_ids)\n","train_data_labels = np.asarray(train_data_labels, dtype = np.int32)\n","\n","print('Sentences: {}\\nLables: {}'.format(len(train_movie_input_ids), len(train_data_labels)))\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["100%|██████████| 149995/149995 [00:43<00:00, 3457.51it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Sentences: 149995\n","Lables: 149995\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"svG44iQJxavY","executionInfo":{"status":"ok","timestamp":1604920073114,"user_tz":-540,"elapsed":1120,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}},"outputId":"c179c800-2e8c-406c-9025-53d5035e28c6","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 특정값 하나 뽑아서 볼게\n","idx = 5\n","\n","input_id = train_movie_input_ids[idx]\n","attention_mastk = train_movie_attention_masks[idx]\n","token_type_id = train_movie_token_type_ids[idx]\n","\n","print(input_id)\n","print(attention_mask)\n","print(token_type_id)\n","print(tokenizer.decode(input_id))\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[   101   9247   8867  32158  23811    100    124  24982  17655   9757\n","  55511    122  23321  10954  24017  12030    129 106249  24974  30858\n","  18227    119    100    119    119    119   9353  30134  21789  12092\n","   9519 118671 119169    119    102      0      0      0      0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0]\n","[CLS] 막 걸음마 [UNK] 3세부터 초등학교 1학년생인 8살용영화. [UNK]... 별반개도 아까움. [SEP] [PAD] [PAD] [PAD] [PAD]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vs5N0cinw4xd","executionInfo":{"status":"ok","timestamp":1604922587062,"user_tz":-540,"elapsed":3577,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["class TFBertClassifier(tf.keras.Model):\n","    def __init__(self, model_name, dir_path, num_class ):\n","        super(TFBertClassifier, self).__init__()\n","\n","        self.bert = TFBertModel.from_pretrained(model_name, cache_dir= dir_path)\n","        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n","        self.classifier = tf.keras.layers.Dense(num_class,\n","                                                kernel_initializer = tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range),\n","                                                name = 'classifier')\n","        \n","        # dense수는 class수만큼. initialzer는 trunc로 근데 bert로 불러올려고\n","\n","    def call(self, inputs, attention_mask = None, token_type_ids = None, training = False):\n","        outputs = self.bert(inputs, attention_mask = attention_mask, token_type_ids = token_type_ids)\n","        pooled_output = outputs[1]\n","        pooled_output = self.dropout(pooled_output, training= training)\n","        logits = self.classifier(pooled_output)\n","\n","        return logits\n","\n","cls_model = TFBertClassifier(model_name = 'bert-base-multilingual-cased',\n","                             dir_path = 'bert_ckpt',\n","                             num_class = 2)\n"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"T69QQC_Uw28H","executionInfo":{"status":"ok","timestamp":1604922587064,"user_tz":-540,"elapsed":3365,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":["optimizer = tf.keras.optimizers.Adam(3e-5)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","cls_model.compile(optimizer = optimizer, loss = loss, metrics = [metric])"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQJguadKhrSS","outputId":"fe39416b-19b7-47fa-8bc7-310e921de2ea","colab":{"base_uri":"https://localhost:8080/"}},"source":["model_name = ' tf2-bert_naver_movie'\n","\n","es_callback = EarlyStopping(monitor = 'val_accuracy', min_delta = 0.0001, patience=2)\n","\n","checkpoint_path = os.path.join('./', model_name, 'weights.h5')\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","if os.path.exists(checkpoint_dir):\n","    print('{} Directory already exists\\n'.format(checkpoint_dir))\n","else:\n","    os.makedirs(checkpoint_dir, exist_ok = True)\n","    print('{} Directory already complete\\n'.format(checkpoint_dir))\n","\n","cp_callback = ModelCheckpoint(checkpoint_path, monitor = 'val_accuracy',\n","                              verbose = 1, \n","                              save_best_only = True,\n","                              save_weights_only = True)     # verbose=1로 설명 듣자\n","\n","history = cls_model.fit(train_movie_inputs, train_data_labels,\n","                        epochs = NUM_EPOCHS,\n","                        batch_size = BATCH_SIZE,\n","                        validation_split= VALID_SPLIT,\n","                        callbacks = [es_callback, cp_callback])\n","\n","print(history.history)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["./ tf2-bert_naver_movie Directory already exists\n","\n","Epoch 1/3\n"," 856/3750 [=====>........................] - ETA: 27:42 - loss: 0.5115 - accuracy: 0.7407"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PaO33a6ChrSW"},"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend(['loss', 'val_loss'])\n","plt.show()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"70LmiYEK2eY6"},"source":["\n","input_ids = []\n","attention_masks = []\n","token_type_ids = []\n","test_data_labels = []\n","\n","for test_sentence, test_label in tqdm(zip(test_data['document'], test_data['label'])):\n","    try:\n","        input_id, attention_mask, token_type_id = bert_tokenizer(test_sentence, MAX_LEN)\n","\n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","        test_data_labels.append(test_label)\n","    except Exception as e:\n","        print(e)\n","        pass\n","\n","\n","test_movie_input_ids = np.array(input_ids, dtype = int) \n","test_movie_attention_masks = np.array(attention_masks, dtype = int)\n","test_movie_token_type_ids = np.array(token_type_ids, dtype = int)\n","test_movie_inputs = (test_movie_input_ids, test_movie_attention_masks,train_movie_token_type_ids)\n","test_data_labels = np.asarray(test_data_labels, dtype = np.int32)\n","\n","print('Sentences: {}\\nLables: {}'.format(len(test_movie_input_ids), len(test_data_labels)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ViDLAZWC26Gl"},"source":["cls_model.evluate(test_movie_inputs,test_data_labels , batch_size = 1024)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UfubbrJBxhDa"},"source":["## 모델 학습"]},{"cell_type":"code","metadata":{"id":"Df3MZ75XhrSa","executionInfo":{"status":"ok","timestamp":1604919874595,"user_tz":-540,"elapsed":97039,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":[""],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"PvBygAVGhrSf","executionInfo":{"status":"ok","timestamp":1604919874596,"user_tz":-540,"elapsed":97039,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":[""],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SzUB0CmvhrSh","executionInfo":{"status":"ok","timestamp":1604919874598,"user_tz":-540,"elapsed":97037,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":[""],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z2C2pRPOxzqm"},"source":["## 모델 평가"]},{"cell_type":"code","metadata":{"id":"6DB2-EymhrSp","executionInfo":{"status":"ok","timestamp":1604919874599,"user_tz":-540,"elapsed":97036,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":[""],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLu7M6TohrSt","executionInfo":{"status":"ok","timestamp":1604919874600,"user_tz":-540,"elapsed":97034,"user":{"displayName":"박성흠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9Cj6D2h5-5RlAvSAB86oovrFwm59mGWcldbpX=s64","userId":"17794821546298080880"}}},"source":[""],"execution_count":11,"outputs":[]}]}